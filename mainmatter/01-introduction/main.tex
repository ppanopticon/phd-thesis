\chapter{Introduction}
%\epiquote{Websites that collect quotes are full of mistakes and never check original sources}{Randall Munroe, XKCD}
The term \emph{multimedia} describes the combination of different forms of content -- also called \emph{modalities} -- into a single, sensory experience that carries a higher level semantic. Those modalities include but are not limited to textual, visual (e.g., images or videos) or aural (e.g, music, sound effects, speech) input. In addition, signals produced by various sensors and devices can also be seen as media modalities, even though direct experience by a human consumer may require pre-processing through specialized hard- and software.

People interact with multimedia on a daily basis when watching videos on Netflix or YouTube, when listening to music on Spotify or when browsing a private image collection on their laptop. Multimedia content makes up a large part of today's Internet and its mere omnipresence makes it a major driving force behind its growth, as both volume and variety increases steadily. A large contributing factor are social media platforms, where users act both as consumers and producers of content. Current estimates~\footnote{Source: Statista.com, ``Social media usage worldwide'', January 2021} suggest, that there are roughly 4.66 billion active Internet users worldwide, of which 4.2 million can be considered active social media users. Facebook alone contributed to $144000$ uploaded images per minute in 2020. And many more of these  platforms, such as \emph{Instagram} org \emph{Twitter} serve billions of users with mixed, self-made content involving text, images, videos or a combination thereof. A similar study found~\footnote{Source: Statista.com, ``Big Data'', January 2021}, that by 2025 we will produce a yearly amount of 175 Zettabytes (i.e, $10^{21}$ bytes).

Given these numbers, the need for efficient and effective tools for \emph{managing}, \emph{manipulating}, \emph{searching}, \emph{exploring} and \emph{analysing} multimedia data corpora comes at no surprise.

\section{Working with Multimedia Data}

On a very high level, multimedia data collections consist of individual (raw) multimedia items, such as video, image or audio files. Each item, in turn, comprises of \emph{content}, \emph{annotations} and \emph{metdata}. Unlike traditional data collections that contain only text and numbers, the content of the multimedia item itself is unstructured, which gives rise to a need for compact \emph{feature representations} that can be handled by data processing systems~\cite{Zahalka:2014towards}. Traditionally, such feature representations are numerical vectors $f_i \in \mathbb{R}^d$ but could in theory be any mathematical object that can be processed by a computer, such as a tensor. Annotations, metdata and features may either be generated upon the item's creation (e.g., for technical metadata), as a result of data-processing and analysis or by manually adding the information at some stage of the item's lifecycle. 

\subsection{Multimedia Analysis \& Retrieval}

Multimedia analysis and multimedia retrieval are two sides of the same coin and are often used interchangeably in literature. Both areas of research have their roots in \emph{computer vision} and \emph{pattern recognition}, which started in the 1970s and deal with the automated, computer-aided analysis of visual information on images and videos. Classical tasks involve automatic classification of images, such as, labeling images as either depicting a dog or a cat. For the purpose of this thesis, and -- one could argue -- as a general definition, the distinction can be put as follows:

Multimedia analysis deals with the extraction and processing of meaningful feature representations from media items. In the early days of computer vision, a lot of effort went into the engineering of feature representations that appropriately captured certain aspects of a media item, such as the colour distribution, texture or keypoints in an image. With the advent of deep learning, the extraction of such features from, e.g., images could largely be automated through neural network architectures such as the \emph{Convolutional Neural Network (CNN)}. Once a feature has been obtained, it can be used to perform different tasks such as classification, clustering or statistical analysis, all of which fall under the umbrella of multimedia analysis.

Multimedia retrieval can be seen a as a very special use cases of multimedia analysis. It's a dedidcated field of research that deals with the act of searching and finding an item of interest within a large multimedia collection. Even though this may sound like the main function of a database, it is a very different task for multimedia than it is for structured data~\cite{Blanken:2007multimedia}. On the one hand, the structure of a relational database is a given and using languages like SQL, a user can specify exactly what elements from the database should be selected using predicates that either match or don't match the items in a collection. Retrieving multimedia data, on the other hand, comes with indirections due to the feature representations used for querying and the \emph{semantic gap} associated with them. One model to work with the feature representations is by obtaining a (dis-)similarity score from the features, a process referred to as ranking. So in addition to extraction of appropriate features and effective ranking algorithsm, multimedia retrieval also concerns itself with aspects such as query formulation, results presentation, data storage etc.

\subsection{Multimedia Analytics}
In simple terms, \emph{multimedia analytics} can be seens as a combination of methods from multimedia analysis with visual analytics. While multimedia analysis deals with the different media types and how meaningful representations can be extracted from them, visual analytics deals with the user's interaction with the data~\cite{Chinchor:2010multimedia}. Multimedia analytics aim at generating knowledge from the multimedia data, for example, by summarizing data or by offering means to explore it.


\section{Research Gap and Objective}

The starting point for the research described in this thesis is the current state-of-the-art for data management in multimedia retrieval and analytics as briefly touched upon in the previous sections. Starting from the models and solutions proposed in \cite{Giangreco:2016adam,Giangreco:2018thesis} and motivated by the ``Ten Research Questions for Scalable Multimedia Analytics''~\cite{Jonson:2016}, this thesis challenges three basic assumptions currently employed and operated upon and explores the ramifications of doing so, with the higher level goal of furthering convergence between research conducted in \emph{multimedia retrieval}, \emph{multimedia analysis} and \emph{multimedia analytics} on the one hand, and classical \emph{database systems} on the other. The assumptions that are being challenged are namely:

\begin{description}
    \item[Assumption 1: Staticity of data collections] Most multimedia retrieval systems today make a clear distinction between an \emph{offline} phase during which media items are analysed, features are generated and derived data is ingested into a data management system, and an \emph{online} phase, during which queries of the database take place. Usually, no changes to the data collection are being made during the online phase. This formal model is advertised by both \cite{Giangreco:2018thesis} and \cite{Rossetto:2018thesis} and to the best of our knowledge, most existing systems explicitly or implicitly function in this manner. This simplification allows for time consuming processes related to feature extraction and indexing to take place separated from any concurrent query activities and eases requirements on transaction isolation. While this is convenient from a perspective of system design, such a mode of operation is limiting when facing data that changes frequently, as is the case, for example, when doing real-time analysis or when having an application with CRUD support.
   
    \item[Assumption 2: Similarity search is nearest neighbor search] Multimedia retrieval relies strongly on a notion of similarity search that is usually expressed as finding the $k$ nearest neighboring feature vectors $\vec{v}_{i \in \left[1,k\right]} \in \mathrm{C}$ to a query vector $\vec{q} \in \mathbb{R}^d$ in a collection $\mathrm{C} \subset \mathbb{R}^d$ given a certain distance function. Very often, metrics such as the Euclidean or the Manhattan distance are employed for this comparison. This is also refered to as the \emph{vector space model}. While this model is very concise and rather simple, it merely allows for ranking of potential results and finding the relevant or desired item(s). This model is, however, limited when looking at tasks such as summarization or structuring of data, as required for multimedia analysis and analytics. Furthermore, there are cases in which features are not real-valued vectors and similarity is not directly related to proximity.

    \item[Assumption 3: User defines execution] Database management systems usually evaluate and select the execution plan for an incoming query during a step that is refered to as \emph{query planning}. The underlying assumption here is that the database system has all the information required to determine the most effective execution plan in terms of cost parameters such as required I/O, CPU and memory usage. In similarity search, this is not the case since, for example, index selection relies on a lot of different aspects that, to some extent, can be parametrized by the client issuing a query or that may be subject to change. Therefore, the index used for executing a query is usually selected manually by the user issuing the query. This limits the amount of optimization that can be applied by the multimedia database system especially in the face of non-static data collections.
\end{description}



\subsection{Motivation}

Teh a


\subsection{Research Questions}

Challenging the aforementioned assumptions raises very specific questions that fundamentaly impact the design of a \emph{multimedia database}. These questions are briefly summarized in \cref{table:research_questions}.

\begin{table}[h!]
    \centering
    \caption{List of research questions resulting from challenging assumptions one, two and three.}
    \begin{tabular}{|c|p{10cm}|c|} 
     \hline
     \textbf{RQ} & \textbf{Question} & \textbf{Related to} \\ [0.5ex] 
     \hline\hline
     1 & Which commonly used, secondary index structures for NNS (e.g., VA~\cite{Weber:1998va}, LSH~\cite{Indyk:1998lsh}, PQ~\cite{jegou:2011pq} based indexes) can cope with dynamic data collections and to what extent? & Assumption 1\\ 
     2 & Can we quantify and estimate how much the retrieval quality of index structures from RQ1 deterioration as changes are being made to the underlying data collections? & Assumption 1 \\ 
     2 & How can we handle secondary index structures from RQ1 for which to expect deteriorated retrieval quality during query planning and execution? & Assumption 1 \\
     4 & How can user knowledge about the the retrieval task at hand be factored into query planning without forcing the user the make explicit choices about how a query should be executed? & Assumption 1 \& 3 \\
     5 & 88 & \\ 
     \hline
    \end{tabular}
    \label{table:research_questions}
\end{table}

Obviously, the list of questions in \cref{table:research_questions} is not exhaustive and many more implications can be derived from the assumptions challenged so far. However, the questions are the one tackled by the research presented in this thesis.


\section{Contribution}

