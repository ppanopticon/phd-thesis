\chapter{Conclusion and Outlook}
\label{chapter:conclusion}
\epiquote{One never notices what has been done; one can only see what remains to be done.}{Marie Curie, 1894}

Inspired by the questions raised in \cite{Jonsson:2016Ten} and the solutions presented by \cite{Giangreco:2018Database}, we set out to challenge some assumptions about the storage, management, and processing of data used in multimedia retrieval and analytics workloads. Most importantly, we called into question that 
\begin{enumerate*}[label=(\roman*), itemjoin={{, }}, itemjoin*={{, and }}, after={{.}}]
    \item multimedia retrieval and analytics only involve \acrshort{nns} in high-dimensional, real-valued vector spaces
    \item that data collections remain static while they are being queried
    \item that  the execution path of a query should be an explicit choice of the user
\end{enumerate*} 
Throughout this Thesis, we tried to take the viewpoint of a database engineer who considers the problems at hand to be data management and processing issues that should be delegated to the underlying \acrshort{dbms} whenever possible \cite{Ferro:2014Bridging,Amsaleg:2014Database}. At the (preliminary) end of our journey, this has led to several contributions:

\begin{enumerate}
    \item We specified a query model based on the notion of generalised, proximity-based operations to support multimedia retrieval and analytics workloads on top of relational algebra (see \Cref{section:generalised_proximity_based_ops}). In our model, we put a special emphasis on the role of functions and \acrlong{dfc}es in query formulation, planning, and execution, and we explore the relationship between these functions and high-dimensional indexes.
    \item We proposed a cost model that takes the expected quality of results produced by approximate index structures into account (see \Cref{section:cost_model}). This cost model exposes the often implicit and opaque trade-off between quality and speed to the system and the user, who can act upon it.
    \item We described a mechanism that can function as a template for integrating and maintaining high-dimensional indexes in a transactional and durable database system (see \Cref{section:hd_index_maintenance}). Such an integration is crucial for supporting workloads that rely on changing data.
    \item We introduced our open-source reference implementation \cottontail{}, which employs the aforenamed, theoretical contributions and more (see \Cref{chapter:cottontaildb}). 
    \item We presented an evaluation that uses \cottontail{} to demonstrate the viability of our approach (see \Cref{chapter:evaluation}). One focus of this evaluation was a direct comparison of \cottontail{} to the vector database Milvus \cite{Wang:2021Milvus}.
    \item We identified important issues and research questions to further the fields of multimedia retrieval and analytics on the one hand and database research on the other, as well as the convergence of the two. These insights also provide guidance for the continued development of \cottontail{}.
\end{enumerate}

\cottontail{} can be considered a classical database in many respects in that it offers traditional database features such as durability and transactionality. Yet its main purpose, until today, has been the storage and management of multimedia metadata and descriptors, the processing of interactive multimedia retrieval query workloads and the serving of data to the user. \cottontail{} has been part of the \vitrivr{} ecosystem \cite{Rossetto:2016Vitrivr,Gasser:2019Multimodal} for several years and its versatile query model has enabled successful participation of \vitrivr{} in many iterations of events like the \acrshort{vbs} \cite{Rossetto:2019Deep,Sauter:2020Combining,Spiess:2021Competitive,Heller:2022Multi} or \acrshort{lsc} \cite{Spiess:2021Exploring,Heller:2020Interactive,Heller:2021Interactive,Spiess:2022Multi}.

The work on \cottontail{} and thus the work presented in this Thesis contributes towards integrating efforts in data management aspects of multimedia retrieval and analytics (\cite{Vrochidis:2019Big} refers to this as multimedia delivery) on the one hand and database research on the other. In its current form, it constitutes an important foundation for current and future research endeavours in various multimedia applications. In addition, we see a huge potential for using both \vitrivr{} and \cottontail{} for practical applications and for educational purposes.

\section{Motivating Scenarios}

In \Cref{chapter:applications} we have described three scenarios that motivate the work presented in this thesis, namely, interactive multimedia retrieval (\Cref{section:application_retrieval}), social media analytics (\Cref{section:application_online_analysis}) and signal analysis in medical imaging through \acrshort{mrf} (\Cref{section:application_mrf}). In this section, we would like to elaborate on how we expect our contributions to benefit those use cases.

The proposed query model can be directly applied to all three applications. In \cite{Huerbin:2020Retrieval,Zihlmann:2021Magnetic} we have used it to solve the \acrshort{mrf} problem by adding support for complex vectors and an inner product distance function defined for this domain. The same model has also enabled the pose-queries described in \cite{Heller:2022Multi}, which rely on the evaluation of nested (distance) functions and which facilitate a new type of multimedia retrieval query in \vitrivr. Furthermore, \cottontail{} powered rather experimental systems such as LifeGraph \cite{Rossetto:2021Exploring}, which speaks to its and the query model's versatility. We expect that the query model in its current state (and with future extensions) can be used to facilitate many additional types of workloads required by multimedia retrieval and analytics applications as, e.g., outlined in \cite{Seebacher:2017Visual}.

The cost model we propose can be used to configure an instance of \cottontail{} to match a specific application using cost policies. For solving the \acrshort{mrf} problem, one would probably put more weight onto quality whereas execution speed remains the focus for interactive retrieval operations. We expect the aspect of quality cost to become more important in the future, especially as new methods allow for a more fine-grained control over the quality versus speed trade-off, e.g., with progressive querying proposed by \cite{Giangreco:2018Database} combined with a user's ability to abort queries early and re-formulate them.

The maintenance of high-dimensional indexes in the face of incremental changes is probably most relevant for the social media analytics use case. In this scenario, changes to the data are inevitable since new content is being produced continuously and must therefore be considered during indexing. Furthermore, changes to the analytics models and insights gained during the process can also lead to changes to the data. However, the proposed mechanisms may also benefit more traditional retrieval scenarios especially when considering \acrshort{crud} applications in which multiple users work on the same data corupus, which they query and alter.

\section{Future Work}

The process of writing this Thesis, the formulation of the theoretical models and the implementation of a system that employs them, has answered several important questions but it has raised even more. Over the course of this project, we came up with many (brave) new ideas concerning both the theoretical foundation and the implementation. We will conclude this chapter by elborating on these ideas.

\subsection{Query Model}

For decades, much effort has been made in the development of different query models for information retrieval and their combination with the Boolean model. However, only few have actually been implemented and put to the test. We consider the query model we have presented to be a first step in combining two worlds in a pragmatic way that opens new avenues to explore. On the one hand, there are many potentially relevant extensions that lead towards a fully fledged Extended Boolean Retrieval Model \cite{Salton:1983Extended}, such as fuzzy queries \cite{Umano:1983Retrieval,Bohm:2001Fast} or similarity joins \cite{Yao:2010K}. One step in realising this could be to consider distances and scores explicit data types that, in addition to basic arithmetics, allow for advanced operations required in this context \cite{Silva:2010SimDB}. On the other hand, a general-purpose multimedia \acrshort{dbms} must also consider query primitives, such as \acrshort{rnns} \cite{Korn:2000Influence}, bichromatic \acrshort{rnns} \cite{Stanoi:2001Discovery} or clustering. Both could prove to be interesting extensions to the proposed framework.

In light of such potential extensions we would like to briefly touch upon the question  \emph{``Is a novel multimedia query language needed for the database to fully support multimedia analytics, or is an extension of classic query languages sufficient?''} \cite{Jonsson:2016Ten} (p. 299, RQ2). Considering the work in this thesis, we can state that all of the functionality required can be expressed by extended relational algebra and therefore be easily translated to \acrshort{sql}. The idea of expressing advanced functionality as mere function invocations can be further extended to other concepts such as fulltext search, as, e.g., done by MS-SQL. However, advanced query paradigms such as clustering and \acrshort{rnns} are difficult or impossible to express in standard \acrshort{sql} and may therefore require language extensions similar to, e.g., common table expressions for recursive queries. While some authors may advertise a dedicated ``information retrieval query language'' \cite{Ferro:2014Bridging}, we tend to argue from personal experience, that an extension of \acrshort{sql} would be preferable to coming up with a new language, simply because \acrshort{sql} is well established, well known, and easy to use.\footnote{In fact, a \acrshort{sql} interface is among the top feature requests for \cottontail{}.}

\subsection{Multimedia Indexing}

We have shown in our evaluation that the ability to cope with changes to the data at an index level may not be sufficient to maintain a constant quality of service, at least for the index structures considered in our experiments. However, we strongly believe that the argument can be extended to other indexes. We see a major challenge in tuning hyperparameters of an index to the concrete collections at hand. As it seems, the factors that determine the right choice are not only tied to the dimensionality of the vectors but also to the size of the collection and the distribution of data within it. Until now, this problem has not been systematically considered and finding the set of parameters that yields the best results in terms of performance and quality has been a manual task that relies on the experience of the user and empirical analysis. This may work well if a collection remains static, but fails once a collection is subject to accumulating changes that cannot be dealt with, given the set of hyperparameters. Hence, rather than regarding these parameters as fixed properties, a multimedia \acrshort{dbms} should move towards dynamically adapting them to its needs. In order for this to work, however, we require a better understanding of the relationship between those parameters, the properties of a collection, and the quality of the results. And we would like to take the opportunity to encourage researchers who work in high-dimensional indexing to put more emphasis on these aspects.

In addition, the traditional model applied to indexing is that of a system user or database administrator creating indexes based on their requirements. Due to the complex interdependencies we have observed, this might not work well for high-dimensional indexes which is why we also see multimedia indexing as a very interesting area for the application of Database Cracking techniques \cite{Idreos:2007Database,Schuhknecht:2013Uncracked} wherein the \acrshort{dbms} tries to learn indexes and optimised storage views based on query workloads. To some extent, our adaptation of the cost model and state of existing indexes based on the outcome of queries can be regarded as the first small steps in such a direction.

\subsection{Storage Model}
Over the course of \cottontail{}'s lifetime, we have gone through three different versions of storage engines (four, if one counts the experimental one). A key takeaway from these projects is that the organisation and layout of data on disk has a great impact on performance and that storage of and access to large, complex data types comes with unique requirements. At a high level, there are two ways to approach this issue, both equally interesting and challenging:

On the one hand, \cite{Giangreco:2018Database} did propose and implement a polystore approach, which delegates storage to different systems that handle a certain type of data- or query-workload particularly well. Such an approach comes with the challenge that transactional guarantees must be provided across different systems. This is a problem tackled by PolyDBMS \cite{Vogt:2021Polystore} systems such as Polypheny-DB \cite{Vogt:2018Polypheny,Vogt:2020Polypheny}. In fact, first steps in such a direction have already been taken with the integration of \cottontail{} into Polypheny-DB and they could give rise to interesting new insights for mixed query workloads in the \vitrivr{} context. However, the disadvantage of such an approach is the inherent complexity incurred by relying on different systems, which may complicate the configuration and parametrisation of the individual components for a use case.

On the other hand, it would also be worthwhile to devise efficient low-level storage solutions for the different types of data and workloads faced by a multimedia \acrshort{dbms} as this would allow for tighter integration and optimisation of different parts of a system and reduce dependency on external components. The relationship between storage and low-level data organisation on the one hand and performance on the other is well established \cite{Lejsek:2009NVTree,Lejsek:2011NVTree,Hojsgaard:2019Index} and the recent years have seen many interesting strategies to database storage that could be relevant for our purpose (e.g., \cite{Idreos:2012MonetDB,Sears:2012Blsm}). One concrete step we would like to take is serialisation and storage of multiple values in a single chunk or segment. We know from experiments that storing and compressing multiple vectors together can lead to significantly better compression and thus reduced \acrshort{io} for read workloads. Such a storage scheme could also be beneficial to a batched execution model. Furthermore, several specialised storage engines could and should be integrated by an abstraction layer, e.g., as proposed by \cite{Dittrich:2011Towards,Alagiannis:2014H2O} and (to some extent) implemented by \cottontail.

\subsection{Cost Model and Query Planning}
By making the cost of impaired quality explicit, we have opened an interesting avenue for future research. Thus far, we have only considered rather simple cases in which an approximate index structure is used to satisfy a \acrshort{nns} or range search query. In addition to making these estimates more accurate and exploring the impact of approximation on different types of primitive constructs, it may also be interesting to see how errors introduced into a complex execution plan propagate and influence a final result. If one considers, for example, the case of a (similarity-)join for which both incoming strands are generated by an approximate method -- can we predict how these error (and thus the cost) are combined downstream given an accurate model of the initial error?

Furthermore, we see a potential in using query planning techniques for the optimisation of proximity-based queries and we would like to see how our implementation can cope with a larger solution space involving additional indexes, more complex operations, and functions.

\subsection{Execution Model}
In its early days, \cottontail{} implemented a materialisation model wherein each operator generated intermediate resultsets in memory. This strategy was quickly dropped in favour of the much simpler and less memory-intensive iterator model. However, due to the great potential we see in vectorisation and \acrshort{simd}, especially in light of the recent launch of the Java Vector API\footnote{See https://openjdk.org/jeps/338 and JEPs 414 \& 417; accessed August 2022.}, this model is no longer an optimal fit and a transition to a batch-model should be realised rather sooner than later. Such a transition must, of course, be accompanied and aligned with changes to the storage model, which should also be batched.

Another interesting aspect is that of distributing workloads. \adampro{} used to be inherently distributed \cite{Giangreco:2016Adam,Giangreco:2018Database} whereas \cottontail{} is inherently local. Adding the ability to distribute workloads among different nodes might go a long way in achieving better execution performance, especially for analytical workloads. However, such a step will inevitably raise new research and engineering questions with respect to partitioning and distribution of the data, indexing, and transactionality through, e.g., distributed snapshot isolation \cite{Binnig:2014Distributed}. Generally speaking, we see this as a worthwhile opportunity to rethink \cottontail's data partitioning model from storage to processing with regards to both local parallelisation as well as distribution.

\subsection{Implementation and Vision}
On the implementation side, we see some room for work on the aspect of automated code generation. In order to attain the execution speed, much of the logic is re-implemented over and over again to make use of optimisations for specific data types and to avoid type casting in tight loops. This process could and should be automated either at compile or runtime (code generation). In addition, there are many quality of life features that have been requested for \cottontail{}, e.g., a \acrshort{sql} interface or a management user interface.

As a long-term vision and given the discussions thus far and potential applications ouside the multimedia domain, one should carefully observe the progress in the domain of scientific databases and the convergence between linear and relational algebra. Moving towards a general-purpose, scientific database such as \cite{Stonebraker:2013SciDB,Luo:2018Scalable,Blacher:2022Machine} could bear many benefits for multimedia retrieval and analytics.