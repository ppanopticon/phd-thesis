\chapter{Conclusion \& Outlook}
\label{chapter:conclusion}

\epiquote{Don't adventures ever have an end? I suppose not. Someone else always has to carry on the story.}{J.R.R. Tolkien, 1954}

Inspired by the questions raised in \cite{Jonson:2016Ten} and the solutions presented by \cite{Giangreco:2018Database}, we set out to challenge some assumptions about the storage, management and processing of data used in multimedia retrieval and analytics workloads. Most importantly, we called into question that 
\begin{enumerate*}[label=(\roman*), itemjoin={{, }}, itemjoin*={{, and }}, after={{.}}]
    \item multimedia retrieval and analytics only involves \acrshort{nns} in high-dimensional, real-valued vector spaces
    \item that data collections remain static while they are being queried
    \item that  the execution path of a query should be an explicit choice of the user
\end{enumerate*} 
Throughout this Thesis, we tried to take the viewpoint of a database engineer who considers the problems at hand to be data management and processing issues that should be delegated to the underlying \acrshort{dbms} whenever possible \cite{Ferro:2014Bridging,Amsaleg:2014Database}. At the (preliminary) end of our journey, this has led to several contributions:

\begin{enumerate}
    \item We specified a query model based on the notion of generalised, proximity based operations to support multimedia retrieval and analytics workloads on top of relational algebra (see \Cref{section:generalised_proximity_based_ops}). In our model, we put a special emphasis on the role of functions and \acrlong{dfc}es in query formulation, planning and execution and we explore the relationship between these functions and high-dimensional indexes.
    \item We proposed a cost-model that takes the expected quality of results produced by approximate index structures into account (see \Cref{section:cost_model}). This cost model exposes the often implicit and opaque trade-off between accuracy and speed to the system and the user, who can act upon it.
    \item We described a mechanism that can function as a template for integrating and maintaining high-dimensional indexes in a transactional and durable database system (see \Cref{section:hd_index_maintenance}). Such an integration is crucial for supporting workloads that rely on changing data.
    \item We introduced our open-source reference implementation \cottontail{}, which employs the aforenamed, theoretical contributions (and some more, see \Cref{chapter:cottontaildb}). 
    \item We presented an evalution that uses \cottontail{} to demonstrate the viability of our approach (see \Cref{chapter:evaluation}). One focus of this evaluation was a direct comparison of \cottontail{} to the vector database Milvus \cite{Wang:2021Milvus}.
    \item We identified important issues and research questions to further the fields of multimedia retrieval and analytics on the one hand and database research on the other, as well as the convergence of the two. These insights also provide guidance for the continued development of \cottontail{}.
\end{enumerate}

\cottontail{} can be considered a classical database in many respects in that it offers traditional database features such as durability and transactionality. Yet its main purpose, until today, has been the processing of interactive multimedia retrieval workloads. \cottontail{} has been part of the \vitrivr{} ecosystem \cite{Rossetto:2016Vitrivr,Gasser:2019Multimodal} for several years now and its versatile query model has enabled successful participation of \vitrivr{} in many iterations of events like the \acrshort{vbs} \cite{Rossetto:2019Deep,Sauter:2020Combining,Spiess:2021Competitive,Heller:2022Multi} or \acrshort{lsc} \cite{Spiess:2021Exploring,Heller:2020Interactive,Heller:2021Interactive,Spiess:2022Multi}. In addition, \cottontail{} powered rather experimental systems such as LifeGraph \cite{Rossetto:2021Exploring}, which speaks to its versatility.

The work on \cottontail{} and thus the work presented in this Thesis contributes towards integrating aspects of multimedia retrieval \& analytics on the one hand and database research on the other. In its current form, it constitutes an important foundation for current and future research endeavours in various multimedia applications. In addition, we also see a huge potential for using both \vitrivr{} and \cottontail{} for practical applications and for educational purposes.

\section{Future Work}

The process of writing this Thesis, the formulation of the theoretical models and the implementation of system implementations it comprises of, has answered several important questions but it has raised even more. Over the course of this project, we came-up with many (brave) new ideas on both the model and the implementation side of things. We will conclude this chapter and this Thesis, for that matter, by ellborating on these ideas.

\subsection{Query Model}

Decades of effort have been invested into the development of different query models for information retrieval and their combination with the Boolean model. However, only few have actually been implemented and put to the test. We consider the query model we have presented to be a first step in combining two worlds in a pragmatic way that opens new avenues to explore. On the one hand, there are many potentially relevant extensions that lead towards a full-fledged Extended Boolean Retrieval Model \cite{Salton:1983Extended} such as fuzzy queries \cite{Umano:1983Retrieval,Bohm:2001Fast} or similarity joins \cite{Yao:2010K}. One step in realising this could be to consider distances and scores explicit data types that, in addition to basic arithmetics, allow for advanced operations required in this context \cite{Silva:2010SimDB}. On the other hand, a general purpose multimedia \acrshort{dbms} must also consider query primitives, such as \acrshort{rnns} \cite{Korn:2000Influence}, bichromatic \acrshort{rnns} \cite{Stanoi:2001Discovery} or clustering. Both could prove to be interesting extensions to the proposed framework.

In light of such potential extensions we would like to briefly touch upon the question  \emph{``Is a novel multimedia query language needed for the database to fully support multimedia analytics, or is an extension of classic query languages sufficient?''} \cite{Jonson:2016Ten} (p. 299, RQ2). As far as the work in this Thesis goes, we can state that all of the functionality required can be expressed by an extended relational algebra and therefore be easily translated into \acrshort{sql}. The idea of expressing advanced functionality as mere function invocations can be further extended to other concepts such as fulltext search, as, e.g., done by MS-SQL. However, advanced query paradigms such as clustering and \acrshort{rnns} are difficult or impossible to express in standard \acrshort{sql} and may therefore require language extensions similar to, e.g., common table expressions for recursive queries. While some authors may advertise a dedicated ``information retrieval query language'' \cite{Ferro:2014Bridging}, we tend to argue from a personal experience, that extension of \acrshort{sql} would be preferable to coming up with a new language, simply because \acrshort{sql} is well established, well known and easy to use \footnote{As a matter of fact, a \acrshort{sql} interface is among the top feature requests for \cottontail{}.}.

\subsection{Multimedia Indexing}

We have shown in our evaluation that the ability to cope with changes to the data at an index level may not be sufficient to maintain a constant quality of service, at least for the index structures considered in our experiments. However, we strongly believe that the argument can be extended to other indexes as well. We see a major challenge in the tuning of hyperparameters of an index to the concrete collections at hand. As it seems, the factors that determine the right choice are not just tied to the dimensionality of the vectors but also the size of the collection and the distribution of data within it. Up and until now, this problem has not been systematically considered and finding the set of parameters that yields the best results in terms of performance and quality has been a manual task that relies on experience of the user and empirical analysis. This may work well if a collection remains static but fails once a collection is subject to accumulating changes that cannot be dealt with, given the set of hyperparameters. Hence, rather than regarding these parameters as fixed properties, a multimedia \acrshort{dbms} should move towards dynamically adapting them to its needs. In order for this to work, however, we require a better understanding of the relationship between those parameters, the properties of a collection and the quality of the results. And we would like to take the opportunity to encourage researchers who work in high-dimensional indexing to put more emphasis on these aspects.

In addition, the traditional model applied to indexing is that of a system user or database administrator creating indexes based on their requirements. Due to the complex interdependencies we have observed, this might not work well for high-dimensional indexes which is why we also see multimedia indexing as a very interesting area for applying Database Cracking techniques \cite{Idreos:2007Database,Schuhknecht:2013Uncracked} wherein the \acrshort{dbms} tries to learn indexes and optimised storage views based on query workloads. To some extent, our adapting the cost model and state of existing indexes based on the outcome of queries can be regarded as first baby-steps in such a direction.

\subsection{Storage Model}
Over the course of \cottontail{}'s lifecycle, we have gone through three different storage engine versions (four, if one counts the experimental ones). One takeaway message from these projects are that the organisation and layout of data on disk has a great impact on performance and that storage of and access to large, complex data types comes with unique requirements. At a high level, there two ways to approach this issue, both equally interesting and challenging:

On the one hand, \cite{Giangreco:2018Database} did propose and implement a polystore approach, which delegates storage to different systems that handle a certain type of data- or query-workload particularily well. Such an approach comes with the challenge that transactional guarantees must be provided accross different systems. This is a problem tackled by PolyDBMS systems such as Polypheny-DB \cite{Vogt:2018Polypheny,Vogt:2020Polypheny}. In fact, first steps in such a direction have already been taken with the integration of \cottontail{} into Polypheny-DB and they and could give rise to interesting new insights for mixed query workloads in the \vitrivr{}  context. However, the disadvantage of such an approach is the inherent complexity incurred by relying on different systems, which may complicate the configuration and parametrisation of the individual components for a specific usecase.

On the other hand, it would also be worthwile to come-up with efficient low-level storage solutions for the different types of data and workloads faced by a multimedia \acrshort{dbms} as this would allow for tighter integration and optimisation of different parts of a system and reduce dependency on external components. The relationship between storage and low-level data organisation on the one hand and performance on the other is well-established \cite{Lejsek:2009NVTree,Lejsek:2011NVTree,Hojsgaard:2019Index} and the recent years have seen many interesting strategies to database storage that could be relevant for our purpose (e.g., \cite{Idreos:2012MonetDB,Sears:2012Blsm}). One concrete step we would like to take is serialisation and storage of multiple values in a single chunk or segment. We know from experiments that storing and compressing multiple vectors together can lead to significantly better compression and thus reduced \acrshort{io} for read workloads. Such a storage scheme could also be beneficial for a batched execution model. Furthermore, several, specialised storage engines could and should be integrated by an abstraction layer as, e.g., as proposed by \cite{Dittrich:2011Towards,Alagiannis:2014H2O} and (to some extent) implemented by \cottontail{} .

\subsection{Cost Model and Query Planning}
By making the cost of impaired quality explicit, we have opened an interesting avenue for future research. Thus far, we have only considered rather simple cases in which an approximate index structure is used to satisfy a \acrshort{nns} or range search query. In addition to making these estimates more accurate and exploring the impact of approximation on different types of primitive constructs, it may also be interesting to see how errors introduced into a complex execution plan propagate and influence a final result. If one considers, for example, the case of a (similarity-)join for which both incoming strands are generated by an approximate method. Can we predict how these error (and thus the cost) are combined downstream given an accurate model of the initial error?

Furthermore, we see a potential in using query planning techniques for the optimisation of proximity based queries and we would like to see how our implementation can cope with a larger solution space involving additional indexes, more complex operations and functions.

\subsection{Execution Model}
In its early days, \cottontail{} implemented a materialisation model wherein each operator generated intermediate result sets in memory. This strategy was quickly dropped in favour of the much simpler and less memory-intensive iterator model. However, due to the great potential we see in vectorisation and \acrshort{simd}, especially with eyes to the recent launch of the Java Vector API\footnote{See https://openjdk.org/jeps/338 and JEPs 414 \& 417, Accessed August 2022}, this model is no longer an optimal fit and a transition to a batch-model should be realised rather sooner than later. Such a transition must of course be accompanied and aligned with changes to the storage model, which should also be batched.

Another interesting aspect that falls in of execution is that of distributing workloads. \adampro{} used to be inherently distributed \cite{Giangreco:2016Adam,Giangreco:2018Database} whereas \cottontail{} is inherently local. Adding the ability to distribute workloads among differet nodes might go a long way in achieving better execution performance, especially for analytical workloads. However, such a step will invitabely raise new research and engineering questions with respect to partitioning and distribution of the data, indexing and transactionality through, e.g., distributed snapshot isolation \cite{Binnig:2014Distributed}. Generally speaking, we see this as a worthwile opportunity to rethink \cottontail{} data partitioning model from storage to processing with regards to both local parallelisation as well as distribution.

\subsection{Implementation and Vision}
On the implementation side, we see some room for work on the aspect of automated code generation. In order to attain the execution speed we need, a lot of logic is re-implemented over and over again to make use of optimisations for specific data types and to avoid type casting in tight loops. This process could and should be automated either at compile or runtime (code generation). In addition, there are also many quality of life features that have been requested for \cottontail{}, e.g., a \acrshort{sql} interface or a management user interface.

As a long-term vision and given the discussions thus far and potential applications ouside the multimedia domain, one should carefully observe the progress in the domain of scientific databases and the convergence between linear- and relational algebra. Moving towards a general purpose, scientific database such as \cite{Stonebraker:2013SciDB,Luo:2018Scalable,Blacher:2022Machine} could bear many benefits  for multimedia retrieval and analytics.