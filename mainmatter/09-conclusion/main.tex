\chapter{Conclusion \& Outlook}
\label{chapter:conclusion}

\epiquote{Don't adventures ever have an end? I suppose not. Someone else always has to carry on the story.}{J.R.R. Tolkien, 1954}

Inspired by the questions raised in \cite{Jonson:2016Ten} and the solutions presented by \cite{Giangreco:2018Database}, we set out to challenge some assumptions about the storage and management of multimedia data and the processing of multimedia retrieval and analytics workloads. Most importantly, we called into question that 
\begin{enumerate*}[label=(\roman*), itemjoin={{, }}, itemjoin*={{, and }}, after={{.}}]
    \item multimedia retrieval and analytics only involves \acrshort{nns} in high-dimensional, real-valued vector spaces
    \item that data collections remain static while they are being queried
    \item that  the execution path of a query should be an explicit choice of the user
\end{enumerate*} 
Throughout this Thesis, we tried to take the viewpoint of a database engineer who considers the problems at hand to be data management and processing issues, that should be delegated to the underlying \acrshort{dbms} whenever possible. At the (preliminary) end of our journey, this has led to several contributions:

\begin{enumerate}
    \item We specified a query model based on the notion of generalised, proximity based operations to support multimedia retrieval and analytics workloads on top of relational algebra (see \Cref{section:generalised_proximity_based_ops}). In our model, we put a special emphasis on the role of functions and \acrlong{dfc}es in query formulation, planning and execution and we explore the relationship between these functions and high-dimensional indexes.
    \item We proposed a cost-model that takes the expected quality of results produced by approximate index structures into account (see \Cref{section:cost_model}). This cost model exposes the often implicit trade-off between accuracy and speed transparent to the system and the user, who can act upon it.
    \item We described a mechanism that can function as a template for integrating and maintaining high-dimensional indexes in a transactional and durable database system (see \Cref{section:hd_index_maintenance}). Such an integration is crucial for supporting workloads that rely on changing data.
    \item We introduced our open-source reference implementation \cottontail{}, which employs the aforenamed, theoretical contributions (and some more, see \Cref{chapter:cottontaildb}). 
    \item We presented an evalution that uses \cottontail{} to demonstrate the viability of our approach (see \Cref{chapter:evaluation}). One focus of this evaluation was a direct comparison of \cottontail{} to the vector database Milvus \cite{Wang:2021Milvus} 
    \item We identified important issues and research question to further the fields of multimedia retrieval, analytics and database research as well as the convergence of the two.
\end{enumerate}

\cottontail{} has been part of the \vitrivr{} ecosystem \cite{Rossetto:2016Vitrivr,Gasser:2019Multimodal} for many years now and its versatile query model has enabled successful participation in many iterations of events like the \acrshort{vbs} \cite{Rossetto:2019Deep,Sauter2020:Combining,Spiess2021:Competitive,Heller:2022Multi} or \acrshort{lsc} \cite{Spiess2021:Exploring,Heller2020:Interactive,Heller2021:Interactive,Spiess:2022Multi}. In its role it plays an important foundation for current and future research endeavours in multimedia retrieval and applications. In addition, we also see a huge potential for using both \vitrivr{}Â and \cottontail{} for practical applications and educational purposes.

\section{Future Work}

The process of writing this Thesis and formulating the theoretical models and systems implementations it comprises of has answered many important questions and raised even more. Over the course of this project, we came-up with many new ideas on the model and implementation side of things, that we would like to briefly outline in this section.

\subsection{Query Model}

Decades of effort have been invested into the development of different query models for information retrieval and their combination with the Boolean model. However, only few have actually been implemented and put to the test. We consider the query model we have presented to be a first step in combining two worlds in a pragmatic way that opens new avenues to explore. On the one hand, there are many potentially relevant extensions that lead towards a full-fledged Extended Boolean Retrieval Model \cite{Salton:1983Extended} such as fuzzy queries \cite{Umano:1983Retrieval,Bohm:2001Fast} or similarity joins \cite{Yao:2010K}. One step in realising this could be to consider distances and scores explicit data types that, in addition to basic arithmetics, allow for advanced operations required in this context. On the other hand, a general purpose multimedia \acrshort{dbms} must also consider advanced query primitives, such as \acrshort{rnns} \cite{Korn:2000Influence}, bichromatic \acrshort{rnns} \cite{Stanoi:2001Discovery} or clustering. Both could prove to be invaluable extensions to the proposed model.

In light of such potential extensions we would like to briefly touch upon the question ``Is a novel multimedia query language needed for the database to fully support multimedia analytics, or is an extension of classic query languages sufficient?'' (\cite{Jonson:2016Ten}, p. 299, RQ2). As far as the work in this Thesis goes, we can state that all of the functionality required can be expressed by an extended relational algebra and therefore be easily translated into \acrshort{sql}. The idea of expressing advanced functionality as mere function invocations can be further extended to other concepts such as fulltext search, as, e.g., done by MS-SQL. However, advanced query paradigms such as clustering and \acrshort{rnns} are difficult or impossible to express in standard \acrshort{sql} and may therefore require language extensions similar to, e.g., common table expressions for recursive question. From our personal experience, such an approach would be preferable to coming up with a dedicated query language, simply because \acrshort{sql} is well known and easy to use.

\subsection{Multimedia Indexing}

We have shown in our evaluation that the ability to cope with changes to the data at an index level may not be sufficient to maintain a constant quality of service level, at least for the index structures considered in our experiments (however, we strongly believe that the argument can be extended to other indexes as well). We see a major challenge in the tuning of indexing parameters to the concrete collections at hand. As it seems, important factor that determine the right choice are not just tied to the dimensionality of the vectors but also the size of the collection and the distribution of data within it. Up and until now, this problem has not been systematically considered and finding the set of parameters that yields the best results in terms of performance and quality has been a manual task that relies on experience and empirical analysis. This may work well if a collection remains static but fails once a collection is subject to accumulating changes that cannot be dealt with, given the set of hyperparameters. Hence, rather than regarding these parameters as fixed properties, the multimedia \acrshort{dbms} should move towards dynamically adapting them to its needs. In order for this to work, however, we require a better understanding the relation ship between those parameters and the properties of a collection.

In addition, the traditional model applied to indexing is that of a system user or database administrator creating indexes based in their requirements. Due to the complex interdependencies we have observed, this might not work well for high-dimensional indexes which is why we also see multimedia indexing as a very interesting area for applying Database Cracking techniques \cite{Idreos:2007Database,Schuhknecht:2013Uncracked} wherein the \acrshort{dbms} tries to learn indexes and optimised storage views based on query workloads. To some extent, our adapting the cost model and state of existing indexes based on the outcome of queries can be regarded as baby-steps in such a direction.

\subsection{Storage Model}
Over the course of \cottontail{}'s lifecycle, we have gone through three different storage engine versions (four, if one counts the experimental ones). One takeaway message from these projects are that the organisation and layout of data on disk has a great impact on performance and that storage of and access to large, complex data types comes with unique requirements. At a high level, there two ways to approach this issue, both equally interesting and challenging:

On the one hand, \cite{Giangreco:2018Database} did propose and implement a polystore approach, which delegates storage to different systems that handle a certain type of data- or query-workload particularily well. Such an approach comes with the challenge that transactional guarantees must be provided accross stores. This is a problem addressed by PolyDBMS systems such as Polypheny-DB \cite{Vogt:2018Polypheny,Vogt:2020Polypheny}. In fact, first steps in such a direction have already been taken with the integration of \cottontail into Polypheny-DB and they and could give rise to interesting new insights for mixed query workloads. However, the disadvantage of such an approach is the inherent complexity incurred by relying on different systems, which may complicate the configuration and parametrisation of the individual components.

On the other hand, it would also be worthwile to come-up with efficient low-level storage solutions for the different types of data and workloads faced by a multimedia \acrshort{dbms} as this would allow for tighter integration and optimisation of different parts of a system and reduce dependency on external components. The recent years have seen many interesting strategies to database storage that could be relevant for our purpose (e.g., \cite{Idreos:2012MonetDB,Sears:2012Blsm}). One concrete step we would like to take is serialisation and storage of multiple values in a single unit (chunk, segment). We know from experiments that storing and compressing multiple vectors together can lead to significantly better compression and thus reduced IO. Such a storage scheme could also be beneficial for a batched execution model. Furthermore, several, specialised storage engines could and should be integrated by an abstraction layer as, e.g., as proposed by \cite{Dittrich:2011Toward,Alagiannis:2014H2O} and (to some extent) implemented by \cottontail{}.


\subsection{Execution Model}
In its early days, \cottontail{} implemented a materialization model wherein each operator materialized intermediate result sets. This strategy was quickly dropped in favour of the much simpler and less memory-intensive iterator model. However, due to the great potential we see in vectorisation and \acrshort{simd}, this model is not a perfect fit and a transition to a batch-model should be realised rather sooner than later. Such a transition must of course be aligned with changes to the storage model, which should also be batched.